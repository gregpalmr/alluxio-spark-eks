#
# The Alluxio Open Foundation licenses this work under the Apache License, version 2.0
# (the "License"). You may not use this work except in compliance with the License, which is
# available at www.apache.org/licenses/LICENSE-2.0
#
# This software is distributed on an "AS IS" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
# either express or implied, as more fully set forth in the License.
#
# See the NOTICE file distributed with this work for information regarding copyright ownership.
#

# This should not be modified in the usual case.
fullnameOverride: alluxio

# Docker Image
image: alluxio/alluxio
imageTag: 2.9.3
imagePullPolicy: IfNotPresent

# If deploying Alluxio Enterprise Edition License,
# replace this with the base64 encoded license generated by
#   cat /path/to/license.json | base64 |  tr -d "\n"
#license: PUT_YOUR_LICENSE_BASE64_VALUE_HERE

# Security Context
user: 1000
group: 1000
fsGroup: 1000

# Service Account
#   If not specified, Kubernetes will assign the 'default'
#   ServiceAccount used for the namespace
serviceAccount:

# Image Pull Secret
#   The secrets will need to be created externally from
#   this Helm chart, but you can configure the Alluxio
#   Pods to use the following list of secrets
# eg:
# imagePullSecrets:
#   - ecr
#   - dev
imagePullSecrets:

# Alluxio Common Site Properties
properties:

  # Alluxio master journal properties
  alluxio.master.journal.type: EMBEDDED
  alluxio.master.journal.folder: /journal
  alluxio.master.embedded.journal.addresses: "alluxio-master-0:19200"

  # Alluxio master metastore properties
  alluxio.master.metastore: ROCKS
  alluxio.master.metastore.dir: /metastore

  # Alluxio master root under file system (UFS) properties - other UFSs can be mounted later
  alluxio.master.mount.table.root.ufs: "s3a:/PUT_YOUR_S3_BUCKET_NAME_HERE/alluxio_root_ufs/"
  # If Instance IAM roles are used, you do not need to specify
  # access key ID and secret key. If not, then specify them here:
  #alluxio.master.mount.table.root.option.s3a.accessKeyId: "PUT_YOUR_AWS_ACCESS_KEY_ID_HERE"
  #alluxio.master.mount.table.root.option.s3a.secretKey: "PUT_YOUR_AWS_SECRET_KEY_HERE"

  # Alluxio master other properties
  alluxio.master.persistence.blacklist: ".spark-staging,.hive-staging,_temporary,_SUCCESS,_delta_log,.tmp"
  alluxio.master.audit.logging.enabled: true
  alluxio.master.jvm.monitor.enabled: true

  # Alluxio job_master properties
  alluxio.job.master.worker.timeout: "300sec"

  # Alluxio job_worker properties
  #alluxio.job.worker.threadpool.size: 10

  # Alluxio user properties
  alluxio.user.file.writetype.default: "CACHE_THROUGH"
  alluxio.user.file.readtype.default: "CACHE"
  alluxio.user.file.replication.durable: 1
  alluxio.user.file.persistence.initial.wait.time: -1
  alluxio.user.file.persist.on.rename: true
  alluxio.user.file.replication.durable: 1
  alluxio.user.file.passive.cache.enabled: false
  alluxio.user.file.persistence.initial.wait.time: -1
  alluxio.user.file.persist.on.rename: true
  alluxio.user.file.buffer.bytes: 64MB
  alluxio.user.block.size.bytes.default: 16MB
  alluxio.user.metrics.collection.enabled: true

  # Alluxio worker properties
  alluxio.worker.network.async.cache.manager.threads.max: 15
  alluxio.worker.network.async.cache.manager.queue.max: 30000
  alluxio.worker.network.block.writer.threads.max: 1024
  alluxio.worker.network.block.reader.threads.max: 2048
  alluxio.worker.network.async.cache.manager.queue.max: 25000
  alluxio.worker.network.keepalive.time: "30sec"
  alluxio.worker.network.keepalive.timeout: "30sec"
  alluxio.worker.network.netty.boss.threads: 1
  alluxio.worker.network.netty.worker.threads: 192
  alluxio.worker.jvm.monitor.enabled: true

# Alluxio worker node cache storage configuration
# - For PROD, recommend using local NVMe or SSD for cache storage, never network storage
# - For DEV, using memory or EBS is ok, as long as performance testing is not needed
tieredstore:
  levels:
  - level: 0
    mediumtype: MEM
    path: /dev/shm
    type: emptyDir
    high: 0.95
    low: 0.7

master:
  count: 1  
  properties:
  tolerations:
  #  - key: "PUT_YOUR_TOLERATION_KEY_HERE"
  #    operator: "Equal"
  #    value: "PUT_YOUR_TOLERATION_VALUE_HERE"
  #    effect: "NoSchedule"
  resources:
    limits:
      cpu: "2"
      memory: 6Gi
    requests:
      cpu: "2"
      memory: 6Gi
  ports:
    embedded: 19200
    rpc: 19998
    web: 19999
  jvmOptions:
    - "-Xms6g"
    - "-Xmx6g"
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "19999"
    prometheus.io/path: "/metrics/prometheus/"

jobMaster:
  properties:
  resources:
    limits:
      memory: 2Gi
    requests:
      cpu: "2"
      memory: 2Gi
  jvmOptions:
    - "-Xms2g"
    - "-Xmx2g"

worker:
  properties:
  tolerations:
  #  - key: "PUT_YOUR_TOLERATION_KEY_HERE"
  #    operator: "Equal"
  #    value: "PUT_YOUR_TOLERATION_VALUE_HERE"
  #    effect: "NoSchedule"
  resources:
    limits:      
      cpu: "2"
      memory: 6Gi
    requests:
      cpu: "2"
      memory: 6Gi
  ports:
    rpc: 29999
    web: 30000
  jvmOptions:
    - "-Xms6g"
    - "-Xmx6g"
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "30000"
    prometheus.io/path: "/metrics/prometheus/"

shortCircuit:
  enabled: false
  policy: uuid
  size: 1Mi
  # volumeType controls the type of shortCircuit volume.
  # It can be "persistentVolumeClaim" or "hostPath"
  volumeType: persistentVolumeClaim
  # Attributes to use if the domain socket volume is PVC
  pvcName: alluxio-worker-domain-socket
  accessModes:
    - ReadWriteOnce
  storageClass: standard

jobWorker:
  properties:
  resources:
    limits:      
      memory: 2Gi
    requests:
      cpu: "1"
      memory: 2Gi
  jvmOptions:
    - "-Xms2g"
    - "-Xmx2g"

# Caution: Only use emptyDir for DEV clusters, all data will be lost when pod is restarted.
journal:
  type: "UFS"
  ufsType: "local"
  folder: "/journal"
  volumeType: emptyDir
  size: 1Gi
  medium: ""

# Caution: Only use emptyDir for DEV clusters, all data will be lost when pod is restarted.
metastore:
  volumeType: emptyDir
  size: 1Gi
  mountPath: /metastore
  medium: ""

configmapMounts:

## Secrets
secrets:
  master:
  worker:

##  Metrics System ##

# Settings for Alluxio metrics. Disabled by default.
metrics:
  enabled: true
  # Enable PrometheusMetricsServlet by class name
  PrometheusMetricsServlet:
    enabled: true
  # Pod annotations for Prometheus
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/jobMasterPort: "20002"
    prometheus.io/jobWorkerPort: "30003"
    prometheus.io/path: "/metrics/prometheus/"

# Remote logging server
logserver:
  enabled: false
  replicas: 1
  env:
  # Extra environment variables for the logserver pod
  # Example:
  # JAVA_HOME: /opt/java
  args: # Arguments to Docker entrypoint
    - logserver
  # Properties for the logserver component
  properties:
  resources:
    # The default xmx is 8G
    limits:
      cpu: "2"
      memory: 2Gi
    requests:
      cpu: "1"
      memory: 1Gi
  ports:
    logging: 45600
  hostPID: false
  hostNetwork: false
  # dnsPolicy will be ClusterFirstWithHostNet if hostNetwork: true
  # and ClusterFirst if hostNetwork: false
  # You can specify dnsPolicy here to override this inference
  # dnsPolicy: ClusterFirst
  # JVM options specific to the logserver container
  jvmOptions:
  tolerations:
  #  - key: "PUT_YOUR_TOLERATION_KEY_HERE"
  #    operator: "Equal"
  #    value: "PUT_YOUR_TOLERATION_VALUE_HERE"
  #    effect: "NoSchedule"

  # volumeType controls the type of log volume.
  # It can be "persistentVolumeClaim" or "hostPath" or "emptyDir"
  volumeType: persistentVolumeClaim
  # Attributes to use if the log volume is PVC
  pvcName: alluxio-logserver
  accessModes:
    - ReadWriteOnce
  # storageClass: "standard"
  # If you are dynamically provisioning PVs, the selector on the PVC should be empty.
  # Ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class-1
  # Example:
  selector: {}
  # Attributes to use if the log volume is hostPath
  hostPath: "/tmp/alluxio-logs" # The hostPath directory to use
  # Attributes to use when the log volume is emptyDir
  medium: ""
  size: 100Gi


